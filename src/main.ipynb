{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ddg import Duckduckgo\n",
    "from duckduckgo_search import DDGS\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.models.groq import GroqModel\n",
    "from pydantic_ai.models.ollama import OllamaModel\n",
    "import random\n",
    "import nest_asyncio\n",
    "from pydantic import BaseModel, Field\n",
    "from devtools import debug\n",
    "from schema.schema import ResearchSchema, ScrapeDataSchema\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_model = OllamaModel(model_name=\"llama3.2:latest\")\n",
    "chat_model = ChatOllama(model=\"llama3.2:latest\")\n",
    "# model = GroqModel('llama-3.3-70b-versatile', api_key=os.getenv('GROQ_API_KEY'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "async def _parseScrapedData(scrapedData: str, searchQuery: str)->str:\n",
    "\n",
    "    parse_prompt = f'''\n",
    "\n",
    "    You are an advanced text extraction model. Your task is to extract only the main textual content from the provided scraped webpage data, removing all unrelated elements such as URLs, images, JavaScript, or redundant navigational text. \n",
    "    Focus on delivering clear, meaningful content that reflects the primary information and purpose of the webpage. You will also be given a search query which you will use to find the textual data, from the web scraped data, that is relevant to the search query  \n",
    "    \n",
    "    Instructions:\n",
    "     - Don't modify the text extracted from the data into your own words. Just extract the main textual data as it is.\n",
    "     - Don't say 'Here is the extracted content..' or 'This is a web page...', just remove the unwanted data from the entire input and only output the main textual data as it is.\n",
    "     - Only find out textual data that is relevant to the search query given to you\n",
    "\n",
    "    Search Query: {searchQuery}\n",
    "    Web Scraped Input: (Data to be parsed) \n",
    "\n",
    "    {scrapedData}\n",
    "\n",
    "    Output: \n",
    "\n",
    "    '''\n",
    "    return chat_model.invoke(parse_prompt).content\n",
    "\n",
    "async def _webSearch(query: str)->dict:\n",
    "    print(f\"Recieved Query: {query}. Starting Web Search\")\n",
    "    list_ = DDGS().text(  \n",
    "                keywords = query,\n",
    "                region = 'wt-wt',\n",
    "                safesearch = 'off',\n",
    "                timelimit = '7d',\n",
    "                max_results = 5\n",
    "            )\n",
    "\n",
    "    headers = {\n",
    "    \"Authorization\": f\"Bearer {os.getenv('JINA_API_KEY')}\"\n",
    "    }\n",
    "\n",
    "    data = \"\"\n",
    "\n",
    "    print(f\"Web Search Complete. Starting Scraping\")\n",
    "\n",
    "    for result in tqdm(list_, desc=\"Scraping Links\"):\n",
    "        try:\n",
    "            url = f\"https://r.jina.ai/{result['href']}\"\n",
    "            response = requests.get(url, headers=headers)\n",
    "\n",
    "            parsed_data = await _parseScrapedData(\n",
    "                scrapedData = response.text,\n",
    "                searchQuery = query\n",
    "            )\n",
    "\n",
    "            response.raise_for_status()\n",
    "            data += parsed_data + \"\\n\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching URL {url}: {e}\")\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recieved Query: Tata Steel Vision. Starting Web Search\n",
      "Web Search Complete. Starting Scraping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Links:  20%|██        | 1/5 [00:00<00:03,  1.14it/s]"
     ]
    }
   ],
   "source": [
    "webSearch_agent = Agent(\n",
    "    agent_model,\n",
    "    system_prompt = '''\n",
    "        You are a web searching assistant that does web searches based on query. You must execute the  \n",
    "        You will be given a query and you must use the tool that Searches across the web using query. \n",
    "        You will not answer the query based on your data and will always rely upon web scraping results.\n",
    "    '''\n",
    ")\n",
    "\n",
    "@webSearch_agent.tool\n",
    "async def searchWeb(ctx: RunContext[str], query: str):\n",
    "    \"\"\"Search across the web using query.\n",
    "\n",
    "    Args: \n",
    "\n",
    "        query: query to search\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Recieved Query: {query}. Starting Web Search\")\n",
    "    list_ = DDGS().text(  \n",
    "                keywords = query,\n",
    "                region = 'wt-wt',\n",
    "                safesearch = 'off',\n",
    "                timelimit = '7d',\n",
    "                max_results = 5\n",
    "            )\n",
    "\n",
    "    headers = {\n",
    "    \"Authorization\": f\"Bearer {os.getenv('JINA_API_KEY')}\"\n",
    "    }\n",
    "\n",
    "    data = \"\"\n",
    "\n",
    "    print(f\"Web Search Complete. Starting Scraping\")\n",
    "\n",
    "    for result in tqdm(list_, desc=\"Scraping Links\"):\n",
    "        try:\n",
    "            url = f\"https://r.jina.ai/{result['href']}\"\n",
    "            response = requests.get(url, headers=headers)\n",
    "\n",
    "            parsed_data = await _parseScrapedData(\n",
    "                scrapedData = response.text,\n",
    "                searchQuery = query\n",
    "            )\n",
    "\n",
    "            response.raise_for_status()\n",
    "            data += parsed_data + \"\\n\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching URL {url}: {e}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "results = await webSearch_agent.run(\n",
    "    'Tata Steel Vision'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tata Steel Vision is about Tata Steel Limited's vision and mission statements outlining its strategic goals, values, and culture.\n",
      "\n",
      "**Mission Statement:**\n",
      "\"Tata Steel aims to be the world's best steel company by being the best in everything we do.\"\n",
      "\n",
      "**Vision Statement:**\n",
      "\"To become the global leader in steel production, innovation, and sustainability, while creating long-term value for our stakeholders.\"\n",
      "\n",
      "The mission statement emphasizes Tata Steel's commitment to excellence and its desire to be the best in every aspect of operations. The vision statement highlights the company's ambition to become a global leader in steel production, innovation, and sustainability.\n",
      "\n",
      "Tata Steel core values guide operations:\n",
      "\n",
      "1.  **Integrity:** Tatesh steel commitment ethical practices honesty transparency.\n",
      "2.  **Excellence:** Continuously strive quality technology investments innovative approach.\n",
      "3.  **Responsibility:** Promote sustainable development community well-being.\n",
      "4.  **Innovation:** Fosters growth competitive advantage innovative research-and-development\n",
      "\n",
      "Tata Steel tracks several key performance indicators (KPIs) measure performance:\n",
      "\n",
      "*   Production Output: Increasing production output high quality efficiency\n",
      "*   Customer Satisfaction: Delivering value added services product excellence\n",
      "*   Environmental Performance: Adopt sustainable practices reducing carbon footprint\n",
      "*   Innovation and Development: Investing in research development drive innovation\n",
      "\n",
      "**Financial Model**\n",
      "\n",
      "Tata Steel Limited 5-year forecast outline performance revenue income loss profitability financials, charts provide valuable insights projected growth prospects forward.\n",
      "\n",
      "As Tata Steel continues innovating progress striving become world's leader steel production innovations sustainability, remain committed building better future generations.\n"
     ]
    }
   ],
   "source": [
    "print(results.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_agent = Agent(\n",
    "    model,\n",
    "    result_type = ResearchSchema,\n",
    "    system_prompt = \n",
    "    \n",
    "    '''\n",
    "        You are a research expert agent tasked with conducting a thorough research of a company given to you. You will be given a company name using which you have to do multiple searches using the tools given to you.\n",
    "        During these multiple searches you must use the top 5 links for each search to gather information about a company's and must gather the following information:\n",
    "\n",
    "        1. About the Company\n",
    "            - Industry and Market Segment:\n",
    "                - Primary industry (e.g., Healthcare, Automotive, Retail).\n",
    "                - Sub-segment specialization (e.g., diagnostic tools, electric vehicles, e-commerce logistics).\n",
    "\n",
    "            - Key Offerings:\n",
    "                - Products and services.\n",
    "                - Unique selling propositions (USPs).\n",
    "                - Technological capabilities (e.g., AI-based solutions, IoT integration).\n",
    "\n",
    "            - Strategic Focus Areas:\n",
    "                - Operational improvements (e.g., supply chain optimization).\n",
    "                - Customer experience (e.g., personalized recommendations, chatbots).\n",
    "                - Sustainability initiatives, if applicable.\n",
    "\n",
    "            - Current Technology Adoption:\n",
    "                - Existing AI/ML systems or tools in use.\n",
    "                - Public partnerships with AI/ML providers (e.g., AWS, Azure, Google Cloud).\n",
    "\n",
    "        2. About the Industry\n",
    "            - Market Trends:\n",
    "                - Industry-specific AI and GenAI adoption trends.\n",
    "                - Emerging technologies and use cases in the sector.\n",
    "\n",
    "            - Competitor Analysis:\n",
    "                - Key competitors and their offerings.\n",
    "                - AI/ML initiatives or breakthroughs by competitors.\n",
    "                - Relevant partnerships and collaborations.\n",
    "\n",
    "            - Challenges and Opportunities:\n",
    "                - Pain points the industry faces.\n",
    "                - Opportunities for AI to address these challenges. \n",
    "\n",
    "        You are free to do multiple searches but must provide all the data/ study done and gathered for this company based on the above points.\n",
    "        You are a research expert tasked with gathering information about a company. Use the `searchWeb` tool to search the web and return data for the following queries:\n",
    "\n",
    "    '''\n",
    ")\n",
    "\n",
    "@research_agent.tool\n",
    "async def searchWeb(ctx: RunContext[str], query: str):\n",
    "    \"\"\"Search across the web using query.\n",
    "\n",
    "    Args: \n",
    "\n",
    "        query: query to search\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Recieved Query: {query}. Starting Web Search\")\n",
    "    list_ = DDGS().text(  \n",
    "                keywords = query,\n",
    "                region = 'wt-wt',\n",
    "                safesearch = 'off',\n",
    "                timelimit = '7d',\n",
    "                max_results = 5\n",
    "            )\n",
    "\n",
    "    headers = {\n",
    "    \"Authorization\": f\"Bearer {os.getenv('JINA_API_KEY')}\"\n",
    "    }\n",
    "\n",
    "    data = \"\"\n",
    "\n",
    "    print(f\"Web Search Complete. Starting Scraping\")\n",
    "\n",
    "    for result in tqdm(list_, desc=\"Scraping Links\"):\n",
    "        try:\n",
    "            url = f\"https://r.jina.ai/{result['href']}\"\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            data += response.text + \"\\n\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching URL {url}: {e}\")\n",
    "\n",
    "results = await research_agent.run(\n",
    "    'Tata Steel'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "market-research-agent-m8UpT5-t-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
